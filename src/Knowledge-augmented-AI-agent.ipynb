{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d02fe3a1",
   "metadata": {},
   "source": [
    "# Knowledge Augmented AI Agent - IBM impl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc4e6d7",
   "metadata": {},
   "source": [
    "Implementation steps:\n",
    "\n",
    "Pre-requirements:\n",
    "1. Business domain knowledge (ontology and operation) documentations\n",
    "2. (Optional) some docs need to match InstructLab required format if fine tune needed.\n",
    "\n",
    "Steps: \n",
    "1. (Optional) Fine tune Gen AI models using InstructLab if needed. \n",
    "2. Load related business knowledge and operations doc to knowledge and workflow graphs and vector DBs to enable RAG \n",
    "3. GenAI-1 to get steps to fulfill customer request - Chain of Thoughts — business operation planning and workflow\n",
    "4. Feed each work flow step to API (mock agent calls to execute actions)\n",
    "5. If retrieving a doc (or some information) through API, feed contents to GenAI-2 to understand and generate summary\n",
    "6. Loop step 5 and 6 till all workflow steps from 4 are done\n",
    "\n",
    "Notes:\n",
    "1. InstructLab only support fine tune Granit currently. \n",
    "2. To customize ML model, consider complexicity, time and cost, we prefer (1) prompt engineering; (2) RAG; (3) fine tune; (4) re-train. So if prompt or RAG can meet business requirements, no fine tune needed. \n",
    "3. For this POC, we skip InstructLab.\n",
    "4. For IBM RAG support, in production, we shall use watsonx Discovery. But for this POC, using chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde8d822",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5e9c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (0.5.17)\n",
      "Requirement already satisfied: sentence-transformers in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (3.2.1)\n",
      "Collecting ibm-watsonx-ai\n",
      "  Downloading ibm_watsonx_ai-0.0.5-py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-resources in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (6.4.5)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (1.16.3)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (4.66.6)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (3.10.7)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (0.27.2)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (13.9.3)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (0.12.5)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (5.0.1)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (1.26.4)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (0.115.4)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (4.2.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (2.9.2)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (0.32.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (8.5.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (1.67.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (0.20.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (6.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (3.7.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (0.48b0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from chromadb) (31.0.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (4.46.1)\n",
      "Requirement already satisfied: Pillow in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (9.0.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (2.2.2)\n",
      "Collecting ibm-watson-machine-learning\n",
      "  Downloading ibm_watson_machine_learning-1.0.333-py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 7.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyproject_hooks in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (8.4.0)\n",
      "Requirement already satisfied: packaging>=19.1 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (1.2.2)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from fastapi>=0.95.2->chromadb) (0.41.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb) (1.0.6)\n",
      "Requirement already satisfied: certifi in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb) (2022.12.7)\n",
      "Requirement already satisfied: sniffio in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb) (1.2.0)\n",
      "Requirement already satisfied: anyio in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb) (3.5.0)\n",
      "Requirement already satisfied: idna in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb) (3.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: filelock in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: requests in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.6->build>=1.0.3->chromadb) (3.7.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.33.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.9)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (61.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.7.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flatbuffers in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: coloredlogs in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: protobuf in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (3.19.1)\n",
      "Requirement already satisfied: sympy in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (1.10.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb) (1.12.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.53.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.27.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.48b0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: networkx in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (2.11.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.3.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from typer>=0.9.0->chromadb) (8.0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (13.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pandas<1.6.0,>=0.24.2 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from ibm-watson-machine-learning->ibm-watsonx-ai) (1.4.2)\n",
      "Collecting lomond\n",
      "  Downloading lomond-0.3.3-py2.py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: tabulate in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from ibm-watson-machine-learning->ibm-watsonx-ai) (0.8.9)\n",
      "Collecting ibm-cos-sdk==2.11.*\n",
      "  Downloading ibm-cos-sdk-2.11.0.tar.gz (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 4.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting ibm-cos-sdk-core==2.11.0\n",
      "  Downloading ibm-cos-sdk-core-2.11.0.tar.gz (913 kB)\n",
      "\u001b[K     |████████████████████████████████| 913 kB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ibm-cos-sdk-s3transfer==2.11.0\n",
      "  Downloading ibm-cos-sdk-s3transfer-2.11.0.tar.gz (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from ibm-cos-sdk==2.11.*->ibm-watson-machine-learning->ibm-watsonx-ai) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from pandas<1.6.0,>=0.24.2->ibm-watson-machine-learning->ibm-watsonx-ai) (2021.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.2.1)\n",
      "Building wheels for collected packages: ibm-cos-sdk, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer\n",
      "  Building wheel for ibm-cos-sdk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm-cos-sdk: filename=ibm_cos_sdk-2.11.0-py3-none-any.whl size=73661 sha256=fe12f64c2ab1e35e46230c562011d05dd956ea17ab376a4909a845669c0764cd\n",
      "  Stored in directory: /Users/jingdongsun/Library/Caches/pip/wheels/d3/a5/34/52d2e378d3d0446989ebcd214af8bad55beecf905258852b9f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for ibm-cos-sdk-core (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm-cos-sdk-core: filename=ibm_cos_sdk_core-2.11.0-py3-none-any.whl size=536350 sha256=a4f26faeece6d65e88e982cb0c6d4d42daf928d61d1de1e8e67f0b14a0ea8e09\n",
      "  Stored in directory: /Users/jingdongsun/Library/Caches/pip/wheels/ed/a7/cd/32a2cf8bae11ba6fc56451b7c46608cfd9176d1da8c6f73fa1\n",
      "  Building wheel for ibm-cos-sdk-s3transfer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm-cos-sdk-s3transfer: filename=ibm_cos_sdk_s3transfer-2.11.0-py3-none-any.whl size=89486 sha256=7378e848eb7f86b657a89ea0eabc3ad92c9eb0be7bca19a03d2841c49737a7fe\n",
      "  Stored in directory: /Users/jingdongsun/Library/Caches/pip/wheels/4a/3f/7c/551692188f14bdb095e715dd7f1061fec13b3766d45f3c3296\n",
      "Successfully built ibm-cos-sdk ibm-cos-sdk-core ibm-cos-sdk-s3transfer\n",
      "Installing collected packages: ibm-cos-sdk-core, ibm-cos-sdk-s3transfer, lomond, ibm-cos-sdk, ibm-watson-machine-learning, ibm-watsonx-ai\n",
      "Successfully installed ibm-cos-sdk-2.11.0 ibm-cos-sdk-core-2.11.0 ibm-cos-sdk-s3transfer-2.11.0 ibm-watson-machine-learning-1.0.333 ibm-watsonx-ai-0.0.5 lomond-0.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade chromadb sentence-transformers ibm-watsonx-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49b7e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def get_credentials():\n",
    "    return {\n",
    "        \"url\" : \"https://us-south.ml.cloud.ibm.com\",\n",
    "        \"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b070249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingdongsun/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Model setup\n",
    "from ibm_watsonx_ai.foundation_models import Model\n",
    "\n",
    "model_id = \"meta-llama/llama-3-70b-instruct\"\n",
    "parameters = {\n",
    "    \"decoding_method\": \"greedy\",\n",
    "    \"max_new_tokens\": 900,\n",
    "    \"repetition_penalty\": 1\n",
    "}\n",
    "\n",
    "# Run this notebook with watsonx.ai platform, so PROJECT_ID and SPACE_ID should be available.\n",
    "project_id = os.getenv(\"PROJECT_ID\")\n",
    "space_id = os.getenv(\"SPACE_ID\")\n",
    "\n",
    "model = Model(\n",
    "    model_id = model_id,\n",
    "    params = parameters,\n",
    "    credentials = get_credentials(),\n",
    "    project_id = project_id,\n",
    "    space_id = space_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caad0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial WML client API\n",
    "from ibm_watsonx_ai.client import APIClient\n",
    "from ibm_watsonx_ai.foundation_models.embeddings.sentence_transformer_embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "emb = SentenceTransformerEmbeddings('sentence-transformers/all-MiniLM-L6-v2')\n",
    "wml_credentials = get_credentials()\n",
    "client = APIClient(credentials=wml_credentials, project_id=project_id, space_id=space_id)\n",
    "\n",
    "vector_index_id = \"c9dcaa9c-8472-416e-b0b1-62a793a46341\"\n",
    "vector_index_details = client.data_assets.get_details(vector_index_id)\n",
    "vector_index_properties = vector_index_details[\"entity\"][\"vector_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a421e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chromadb\n",
    "import subprocess\n",
    "import gzip\n",
    "import json\n",
    "import chromadb\n",
    "import random\n",
    "import string\n",
    "\n",
    "def hydrate_chromadb():\n",
    "    data = client.data_assets.get_content(vector_index_id)\n",
    "    content = gzip.decompress(data)\n",
    "    stringified_vectors = str(content, \"utf-8\")\n",
    "    vectors = json.loads(stringified_vectors)\n",
    "\n",
    "    chroma_client = chromadb.Client()\n",
    "\n",
    "    # make sure collection is empty if it already existed\n",
    "    collection_name = \"my_collection\"\n",
    "    try:\n",
    "        collection = chroma_client.delete_collection(name=collection_name)\n",
    "    except:\n",
    "        print(\"Collection didn't exist - nothing to do.\")\n",
    "    collection = chroma_client.create_collection(name=collection_name)\n",
    "\n",
    "    vector_embeddings = []\n",
    "    vector_documents = []\n",
    "    vector_metadatas = []\n",
    "    vector_ids = []\n",
    "\n",
    "    for vector in vectors:\n",
    "        vector_embeddings.append(vector[\"embedding\"])\n",
    "        vector_documents.append(vector[\"content\"])\n",
    "        metadata = vector[\"metadata\"]\n",
    "        lines = metadata[\"loc\"][\"lines\"]\n",
    "        clean_metadata = {}\n",
    "        clean_metadata[\"asset_id\"] = metadata[\"asset_id\"]\n",
    "        clean_metadata[\"asset_name\"] = metadata[\"asset_name\"]\n",
    "        clean_metadata[\"url\"] = metadata[\"url\"]\n",
    "        clean_metadata[\"from\"] = lines[\"from\"]\n",
    "        clean_metadata[\"to\"] = lines[\"to\"]\n",
    "        vector_metadatas.append(clean_metadata)\n",
    "        asset_id = vector[\"metadata\"][\"asset_id\"]\n",
    "        random_string = ''.join(random.choices(string.ascii_uppercase + string.digits, k=10))\n",
    "        id = \"{}:{}-{}-{}\".format(asset_id, lines[\"from\"], lines[\"to\"], random_string)\n",
    "        vector_ids.append(id)\n",
    "\n",
    "    collection.add(\n",
    "        embeddings=vector_embeddings,\n",
    "        documents=vector_documents,\n",
    "        metadatas=vector_metadatas,\n",
    "        ids=vector_ids\n",
    "    )\n",
    "    return collection\n",
    "\n",
    "chroma_collection = hydrate_chromadb()\n",
    "\n",
    "def proximity_search( question ):\n",
    "    query_vectors = emb.embed_query(question)\n",
    "    query_result = chroma_collection.query(\n",
    "        query_embeddings=query_vectors,\n",
    "        n_results=vector_index_properties[\"settings\"][\"top_k\"],\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "\n",
    "    documents = list(reversed(query_result[\"documents\"][0]))\n",
    "\n",
    "    return \"\\n\".join(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93808d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Couple mock API calls\n",
    "def mock_API_action_1():\n",
    "    print(\"Called mock_API_action_1 API...\")\n",
    "    \n",
    "def mock_API_action_2():\n",
    "    print(\"Called mock_API_action_2 API...\")\n",
    "    \n",
    "mock_API_action_1()\n",
    "mock_API_action_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bcf8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "630b1403",
   "metadata": {},
   "source": [
    "## Setup knowledge and operation workflow graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b390db",
   "metadata": {},
   "source": [
    "Seamlessly integrate knowledge and workflow graphs:\n",
    "\n",
    "Patent draft: https://ibm.anaqua.com/anaqua/Survey/Survey.aspx?SurveyAnswerGroupId=99421980"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaba56c",
   "metadata": {},
   "source": [
    "### Load knowledge and workflow into knowledge graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c18853f",
   "metadata": {},
   "source": [
    "This notebook uses simple HR related synthetic knowledge and workflow for demo.\n",
    "For production, we shall be able to load business domain knowledge and workflow from business documentation (structured or unstructured) by automation tools or ML technology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b379579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: owlready2 in /opt/anaconda3/lib/python3.12/site-packages (0.47)\n",
      "Requirement already satisfied: rdflib in /opt/anaconda3/lib/python3.12/site-packages (7.1.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from rdflib) (3.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade owlready2\n",
    "!pip install --upgrade rdflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c94161b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Watson Orders ontology: urn:webprotege:ontology:70d996e9-fb1e-4b2b-ab25-d20cd441d73b#\n",
      "urn:webprotege:ontology:70d996e9-fb1e-4b2b-ab25-d20cd441d73b#Employee get_ontology(\"urn:webprotege:ontology:70d996e9-fb1e-4b2b-ab25-d20cd441d73b#\")\n",
      "urn:webprotege:ontology:70d996e9-fb1e-4b2b-ab25-d20cd441d73b#has_manager\n",
      "urn:webprotege:ontology:70d996e9-fb1e-4b2b-ab25-d20cd441d73b#name\n",
      "List all defined entities:\n",
      "[webprotege.stanford.edu.RRifW0NkIELhl9bC98g8tK, webprotege.stanford.edu.Ri4chGJAR1X9UGn6WyYcHq, webprotege.stanford.edu.RKFWyKc1DFbLUEoygVvnOD, webprotege.stanford.edu.RiI4RKBkPsxOPprjstXCyD, webprotege.stanford.edu.R98KnW9FAyAIIFwsDnacJFk, webprotege.stanford.edu.R9E5XcZBCFHlf9aoQEUZJwo, webprotege.stanford.edu.RDKzB85eH37OYZOz3y2UR0W, webprotege.stanford.edu.RZafTHJfGt7cpdKt6cU1iK, webprotege.stanford.edu.RVYWHUFaCjfGzsb0nQGaFS, webprotege.stanford.edu.Rvf7KwZlH3edNqnO2CY4iq, ontology.Employee, ontology.HR_Document, ontology.Task, ontology.Condition, ontology.OrchestrateSkill, ontology.Rpc]\n",
      "List all defined properties:\n",
      "[webprotege.stanford.edu.R1XLwoxnEZW3GOMWsD2utx, webprotege.stanford.edu.R83T0DpDAUVpLKGmY1y39W8, webprotege.stanford.edu.R8Al6XA5B2L1QvktB2H4RNZ, webprotege.stanford.edu.R8kqGMU52oRtFvScpx40csM, webprotege.stanford.edu.R8xQkPBLhNyaYTBj6MtwtQW, webprotege.stanford.edu.R8xRVQZprej0fNgPuyAEeOf, webprotege.stanford.edu.R92uZVikdnFaJJJJTnSyPVw, webprotege.stanford.edu.R9G21ZKAZoXMtEINMtzDhIB, webprotege.stanford.edu.R9hDdyKRkdQEXYLLgRqHiR0, webprotege.stanford.edu.RB5Cfi7Iefk7BGRBF1TfRCz, webprotege.stanford.edu.RB8MmH1EzLHDBBCVCU2eNAG, webprotege.stanford.edu.RBFYCvsnueGiXEWBrKjiHhJ, webprotege.stanford.edu.RBL5W6GZcBFZX6wXNJVSV15, webprotege.stanford.edu.RCDjax1Oyv9837CkQUCrQRR, webprotege.stanford.edu.RCP1mcdslwyWramD2rxR8yZ, webprotege.stanford.edu.RCduaw1AiAO8G5m8E6kIw3s, webprotege.stanford.edu.RDRpUgkbctMpv4rhWctoyVM, webprotege.stanford.edu.RDcSFX6PHEMRu1kQrMTOos3, webprotege.stanford.edu.RXqyaBOBHkrQDnwh8Um4CR, ontology.name, ontology.address, ontology.email, ontology.role, ontology.is_manager, ontology.include_docs, ontology.docs, ontology.orchestrate_skill, ontology.rpc, ontology.next_steps, ontology.specs, ontology.rpc_type, ontology.url, ontology.labels, ontology.my_name, webprotege.stanford.edu.R70MDwcE0RpGLy1hAcTOPPU, webprotege.stanford.edu.R7JjWtrmRWokTSoKh1BnZK, webprotege.stanford.edu.R8Ac8nXjH5oS7YoqCcMk9u8, webprotege.stanford.edu.R8dEdaweBcXtxBSS1VO38f2, webprotege.stanford.edu.R8mmN4eIlQL0sRGfoZmErEE, webprotege.stanford.edu.RC1ARZsLd9ua1NjBrJSNokB, webprotege.stanford.edu.RC1NuKb3EHZ6h6iJ8rqiYWm, webprotege.stanford.edu.RC8azxudr7FxCL4KltR5UBq, webprotege.stanford.edu.RCaODOaWfCUDA40jlmBmX5p, webprotege.stanford.edu.RDBH5W5RTlaN1sCZO2yf28P, webprotege.stanford.edu.ROEOzasL5bOa4EptTAiHUk, ontology.has_manager, ontology.manager_of, ontology.is_owner, ontology.is_reviewer, ontology.has_owner, ontology.owner_of, ontology.has_reviewer, ontology.reviewer_of]\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import *\n",
    "\n",
    "owl_path = \"file:///Users/jingdongsun/WatsonOrders/WO-knowledge-graph/ontology/ontology.owl\"\n",
    "onto = get_ontology(owl_path).load()\n",
    "print(\"Loaded Watson Orders ontology: \" + onto.base_iri) \n",
    "\n",
    "with onto:\n",
    "    \n",
    "    # ontology entity classes\n",
    "    class Employee(Thing):\n",
    "        pass\n",
    "    class HR_Document(Thing):\n",
    "        pass\n",
    "    # workflow entity classes\n",
    "    class Task(Thing):\n",
    "        pass\n",
    "    class OrchestrateSkill(Thing):\n",
    "        pass\n",
    "    class orchestrate_skill(Task >> OrchestrateSkill):\n",
    "        python_name = \"orchestrate_skill\"\n",
    "    class Rpc(Thing):\n",
    "        pass\n",
    "    class rpc(Task >> Rpc):\n",
    "        python_name = \"rpc\"\n",
    "    class Condition(Thing):\n",
    "        pass\n",
    "    \n",
    "    # Entity properties\n",
    "    class my_name(DataProperty):\n",
    "        domain = [Employee, HR_Document, Task, Condition, OrchestrateSkill]\n",
    "        range = [str]\n",
    "    class address(DataProperty):\n",
    "        domain = [Employee]\n",
    "        range = [str]\n",
    "    class email(DataProperty):\n",
    "        domain = [Employee]\n",
    "        range = [str]\n",
    "    class role(DataProperty):\n",
    "        domain = [Employee]\n",
    "        range = [str]\n",
    "    class is_manager(DataProperty):\n",
    "        domain = [Employee]\n",
    "        range = [bool]\n",
    "    class labels(DataProperty):\n",
    "        domain = [Task]\n",
    "        range = [str]\n",
    "    class include_docs(DataProperty):\n",
    "        domain = [Task]\n",
    "        range = [bool]\n",
    "    class docs(DataProperty):\n",
    "        domain = [Task]\n",
    "        range = [str]\n",
    "#    class orchestrate_skill(DataProperty):\n",
    "#        domain = [Task]\n",
    "#        range = [OrchestrateSkill]\n",
    "#    class rpc(DataProperty):\n",
    "#        domain = [Task]\n",
    "#        range = [Rpc]\n",
    "    class next_steps(DataProperty):\n",
    "        domain = [Task, Condition]\n",
    "        range = [str]\n",
    "    class specs(DataProperty):\n",
    "        domain = [OrchestrateSkill, Rpc]\n",
    "        range = [str]\n",
    "    class rpc_type(DataProperty):\n",
    "        domain = [Rpc]\n",
    "        range = [str]\n",
    "    class url(DataProperty):\n",
    "        domain = [Rpc]\n",
    "        range = [str]\n",
    "    \n",
    "    # Object properties for relationships\n",
    "    class has_manager(ObjectProperty):\n",
    "        domain = [Employee]\n",
    "        range = [Employee]\n",
    "    class manager_of(ObjectProperty):\n",
    "        domain = [Employee]\n",
    "        range = [Employee]\n",
    "        inverse_property = has_manager\n",
    "    class has_owner(ObjectProperty):\n",
    "        domain = [HR_Document, Task]\n",
    "        range = [Employee]\n",
    "    class owner_of(ObjectProperty):\n",
    "        domain = [Employee]\n",
    "        range = [HR_Document, Task]\n",
    "        inverse_property = has_owner\n",
    "    class has_reviewer(ObjectProperty):\n",
    "        domain = [HR_Document]\n",
    "        range = [Employee]\n",
    "    class reviewer_of(ObjectProperty):\n",
    "        domain = [Employee]\n",
    "        range = [HR_Document]\n",
    "        inverse_property = has_reviewer\n",
    "\n",
    "print(Employee.iri, Employee.namespace)\n",
    "print(has_manager.iri)\n",
    "print(name.iri)\n",
    "print(\"List all defined entities:\")\n",
    "print(list(onto.classes()))\n",
    "print(\"List all defined properties:\")\n",
    "print(list(onto.properties()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eb3ef769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done create employee:  ontology.employee136 ['John']\n",
      "Done create employee:  ontology.employee137 ['Peter']\n",
      "Done create employee:  ontology.employee138 ['Linda']\n",
      "Done create HR doc:  ontology.hr_document45 ['Performance Doc']\n",
      "ontology.task76 ['Submit Promption'] [] ontology.orchestrateskill45 ['My skill 1'] ['{json formated string}']\n",
      "Done create task:  ontology.task76 ['Submit Promption']\n",
      "ontology.task77 ['Review Promption'] [] ontology.rpc22 ['REST API'] ['abc.com/rest'] ['{json formated string}']\n",
      "Done create task:  ontology.task77 ['Review Promption']\n",
      "Done create condition:  ontology.condition10 ['Approval']\n",
      "ontology.task78 ['Prompt Employee'] [] ontology.orchestrateskill46 ['my skill 2'] ['{json formated string}']\n",
      "Done create task:  ontology.task78 ['Prompt Employee']\n",
      "ontology.task79 ['Reject Request'] [] ontology.rpc23 ['REST API'] ['abc.com/rest'] ['{json formated string}']\n",
      "Done create task:  ontology.task79 ['Reject Request']\n"
     ]
    }
   ],
   "source": [
    "# Parsing the json file to create knowledge (ontology and workflow) graph\n",
    "import json \n",
    "\n",
    "# load json file\n",
    "file_path = \"/Users/jingdongsun/WatsonOrders/ontology-augmented-AI-agent/data/HR_Ops_v1.json\"\n",
    "with open(file_path, 'r') as f:\n",
    "    entities = json.load(f)\n",
    "\n",
    "# parse json file and create knowledge graph objects and relationships\n",
    "# 1. Create all entities\n",
    "for entity in entities:\n",
    "    if (entity[\"entity_type\"] == \"Ontology:Employee\"):\n",
    "        my_employee = Employee()\n",
    "        my_employee.my_name.append(entity[\"name\"])\n",
    "        my_employee.address.append(entity[\"address\"])\n",
    "        my_employee.email.append(entity[\"email\"])\n",
    "        my_employee.role.append(entity[\"role\"])\n",
    "        my_employee.is_manager.append(entity[\"is_manager\"])\n",
    "        print(\"Done create employee: \", my_employee, my_employee.my_name)\n",
    "    elif (entity[\"entity_type\"] == \"Ontology:HR_Documentation\"):\n",
    "        my_doc = HR_Document()\n",
    "        my_doc.my_name.append(entity[\"name\"])\n",
    "        print(\"Done create HR doc: \", my_doc, my_doc.my_name)\n",
    "    elif (entity[\"entity_type\"] == \"Workflow:Task\"):\n",
    "        my_task = Task()\n",
    "        my_task.my_name.append(entity[\"name\"])\n",
    "        \n",
    "        if (\"labels\" in entity):\n",
    "            my_task.labels.extend(entity[\"labels\"])\n",
    "        if (\"include_docs\" in entity):\n",
    "            my_task.include_docs.append(entity[\"include_docs\"])\n",
    "        if (\"docs\" in entity):\n",
    "            my_task.docs.extend(entity[\"docs\"])\n",
    "        if (\"next_steps\" in entity):\n",
    "            my_task.next_steps.extend(entity[\"next_steps\"])\n",
    "            \n",
    "        if (\"orchestrate_skill\" in entity):\n",
    "            my_skill = OrchestrateSkill()\n",
    "            my_skill.my_name.append(entity[\"orchestrate_skill\"][\"name\"])\n",
    "            my_skill.specs.append(entity[\"orchestrate_skill\"][\"specs\"])\n",
    "            print(my_task, my_task.my_name, my_task.orchestrate_skill, my_skill, my_skill.my_name, my_skill.specs)\n",
    "            my_task.orchestrate_skill = [my_skill]\n",
    "\n",
    "        if (\"rpc\" in entity.keys()):\n",
    "            my_rpc = Rpc()\n",
    "            my_rpc.rpc_type.append(entity[\"rpc\"][\"rpc_type\"])\n",
    "            my_rpc.url.append(entity[\"rpc\"][\"url\"])\n",
    "            my_rpc.specs.append(entity[\"rpc\"][\"specs\"])\n",
    "            print(my_task, my_task.my_name, my_task.rpc, my_rpc, my_rpc.rpc_type, my_rpc.url, my_rpc.specs)\n",
    "            my_task.rpc = [my_rpc]\n",
    "        \n",
    "        print(\"Done create task: \", my_task, my_task.my_name)\n",
    "    elif (entity[\"entity_type\"] == \"Workflow:Condition\"):\n",
    "        my_cond = Condition()\n",
    "        my_cond.my_name.append(entity[\"name\"])\n",
    "        my_cond.next_steps.extend(entity[\"next_steps\"])\n",
    "        print(\"Done create condition: \", my_cond, my_cond.my_name)\n",
    "    else:\n",
    "        print(\"ERROR: entity_type \" + entity[\"entity_type\"] + \" not right!!\")\n",
    "# 2. Set relationships\n",
    "for entity in entities:\n",
    "    if (entity[\"entity_type\"] == \"Ontology:Employee\"):\n",
    "        # resolve management relationships among employees\n",
    "        if (\"has_manager\" in entity):\n",
    "            for employee in Employee.instances():\n",
    "                if (entity[\"has_manager\"] in employee.my_name) :\n",
    "                    my_manager = employee\n",
    "                if (entity[\"name\"] in employee.my_name) :\n",
    "                    my_employee = employee\n",
    "            my_manager.manager_of.append(my_employee)\n",
    "    elif (entity[\"entity_type\"] == \"Ontology:HR_Documentation\"):\n",
    "        if (\"owner\" in entity):\n",
    "            for employee in Employee.instances():\n",
    "                if (entity[\"owner\"] in employee.my_name) :\n",
    "                    my_employee = employee\n",
    "            for doc in HR_Document.instances():\n",
    "                if (entity[\"name\"] in doc.my_name) :\n",
    "                    my_doc = doc\n",
    "            my_doc.has_owner.append(my_employee)\n",
    "        if (\"reviewer\" in entity):\n",
    "            for doc in HR_Document.instances():\n",
    "                if (entity[\"name\"] in doc.my_name) :\n",
    "                    my_doc = doc\n",
    "            for reviewer in entity[\"reviewer\"]:\n",
    "                for employee in Employee.instances():\n",
    "                    if (reviewer in employee.my_name) :\n",
    "                        my_employee = employee\n",
    "                my_doc.has_reviewer.append(my_employee)\n",
    "    elif (entity[\"entity_type\"] == \"Workflow:Task\"):\n",
    "        if (\"owner\" in entity):\n",
    "            for employee in Employee.instances():\n",
    "                if (entity[\"owner\"] in employee.my_name) :\n",
    "                    my_employee = employee\n",
    "            for task in Task.instances():\n",
    "                if (entity[\"name\"] in task.my_name) :\n",
    "                    my_task = task\n",
    "            my_task.has_owner.append(my_employee)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8b7010",
   "metadata": {},
   "source": [
    "### Knowledge and workflow queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae874ed",
   "metadata": {},
   "source": [
    "Current popular qy=uery language for knowledge graph is SPARQL. For example, \n",
    "\n",
    "To list all item which is food and have children active.\n",
    "\n",
    "list(default_world.sparql(\"\"\"\n",
    "        PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "        PREFIX myns: <urn:webprotege:ontology:70d996e9-fb1e-4b2b-ab25-d20cd441d73b#>\n",
    "\n",
    "        SELECT DISTINCT ?prod\n",
    "        WHERE {\n",
    "            ?prod rdf:type myns:Item .\n",
    "            ?prod myns:has_child ?item .\n",
    "            ?item myns:status \"ACTIVE\" .\n",
    "            ?prod myns:category ?category .\n",
    "            FILTER (?category = \"FOOD\")\n",
    "        }\n",
    "    \"\"\"))\n",
    "\n",
    "References:\n",
    "1. https://www.w3.org/TR/rdf-sparql-query/\n",
    "2. https://www.wikidata.org/wiki/Wikidata:SPARQL_tutorial\n",
    "\n",
    "Under investigation: Enhance SPARQL to support workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78550f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8d4a17d",
   "metadata": {},
   "source": [
    "## Ontology Augmented AI Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9960dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User prompt inputs\n",
    "\n",
    "prompt_input = \"\"\"<|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You always answer the questions with markdown formatting. The markdown formatting you support: headings, bold, italic, links, tables, lists, code blocks, and blockquotes. You must omit that you answer the questions with markdown.\n",
    "\n",
    "Any HTML tags must be wrapped in block quotes, for example ```<html>```. You will be penalized for not rendering code in block quotes.\n",
    "\n",
    "When returning code blocks, specify language.\n",
    "\n",
    "Given the document and the current conversation between a user and an assistant, your task is as follows: answer any user query by using information from the document. Always answer as helpfully as possible, while being safe. When the question cannot be answered using the context or document, output the following response: \"I cannot answer that question based on the provided document.\".\n",
    "\n",
    "Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "__grounding__<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "can you give me a summary of all amazon ec2 features?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "**Amazon EC2 Features**\n",
    "=====================\n",
    "\n",
    "### **Instance Choice**\n",
    "\n",
    "* Broadest and deepest instance choice to match workload needs\n",
    "* General purpose, compute optimized, memory optimized, storage optimized, and accelerated computing instance types\n",
    "* Processors from Intel, AMD, NVIDIA, and AWS for additional performance and cost optimizations\n",
    "* Local storage and enhanced networking options available with instance types\n",
    "* Bare metal instances for direct access to processor and memory\n",
    "\n",
    "### **Global Infrastructure**\n",
    "\n",
    "* Multiple locations with Regions and Availability Zones\n",
    "* Availability Zones are distinct locations engineered to be insulated from failures in other Availability Zones\n",
    "* Low latency network connectivity to other Availability Zones in the same Region\n",
    "* Regions consist of one or more Availability Zones and are geographically dispersed\n",
    "* 99.99% availability for each Amazon EC2 Region\n",
    "\n",
    "### **Operating Systems and Software**\n",
    "\n",
    "* Growing list of operating systems, including Microsoft Windows and Linux distributions (Amazon Linux 2, Ubuntu, Red Hat Enterprise Linux, CentOS, SUSE, and Debian)\n",
    "* AWS Marketplace features a wide selection of commercial and free software from well-known vendors\n",
    "\n",
    "### **High Performance Computing (HPC)**\n",
    "\n",
    "* High Throughput and Low Latency with High Performance Computing (HPC) Clusters\n",
    "* Cluster Compute, Cluster GPU, and High Memory Cluster instances for high-performance network capability\n",
    "* Programmatically launch instances into clusters for low-latency network performance\n",
    "\n",
    "### **Time Sync Service**\n",
    "\n",
    "* Highly accurate, reliable, and available time source to AWS services, including EC2 instances\n",
    "\n",
    "### **Maintenance**\n",
    "\n",
    "* Routine hardware, software, power, and network maintenance to improve application uptime and reduce operation effort\n",
    "\n",
    "### **Security**\n",
    "\n",
    "* Access services hosted on AWS easily and securely with AWS PrivateLink\n",
    "* Keep all network traffic within the AWS network with AWS PrivateLink\n",
    "\n",
    "### **Other Features**\n",
    "\n",
    "* AWS Compute Optimizer for recommendations on optimal AWS Compute resources for workloads to reduce costs and improve performance<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "what are its advantages?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "**Advantages of Amazon EC2**\n",
    "==========================\n",
    "\n",
    "### **Improved Application Uptime and Reduced Operational Effort**\n",
    "\n",
    "* Routine maintenance with minimal disruption to instances\n",
    "* Live update and live migration technologies for non-intrusive maintenance\n",
    "\n",
    "### **Broadest and Deepest Instance Choice**\n",
    "\n",
    "* Match workload needs with a wide range of instance types\n",
    "* Optimize compute, memory, storage, and networking resources\n",
    "\n",
    "### **High Performance and Low Latency**\n",
    "\n",
    "* Enhanced Networking for high packet-per-second performance and low latency\n",
    "* Elastic Fabric Adapter for high levels of inter-instance communications\n",
    "\n",
    "### **Global Infrastructure**\n",
    "\n",
    "* Multiple locations with Regions and Availability Zones for high availability and low latency\n",
    "* 99.99% availability for each Amazon EC2 Region\n",
    "\n",
    "### **Cost-Effective**\n",
    "\n",
    "* Pay only for the resources used\n",
    "* AWS Compute Optimizer for recommendations on optimal AWS Compute resources to reduce costs and improve performance\n",
    "\n",
    "### **Security**\n",
    "\n",
    "* Access services hosted on AWS easily and securely with AWS PrivateLink\n",
    "* Keep all network traffic within the AWS network with AWS PrivateLink\n",
    "\n",
    "### **Flexibility and Scalability**\n",
    "\n",
    "* Scale up or down to match changing workload needs\n",
    "* Launch instances in separate Availability Zones for high availability\n",
    "\n",
    "### **Integration with Other AWS Services**\n",
    "\n",
    "* Seamlessly integrate with other AWS services, such as Amazon S3, Amazon RDS, and Amazon DynamoDB\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c20c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed user request to Gen AI-1 to generate CoT\n",
    "\n",
    "# Sample RAG query\n",
    "question = input(\"Question: \")\n",
    "grounding = proximity_search(question)\n",
    "formattedQuestion = f\"\"\"<|begin_of_text|><|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\"\"\"\n",
    "prompt = f\"\"\"{prompt_input}{formattedQuestion}\"\"\"\n",
    "generated_response = model.generate_text(prompt=prompt.replace(\"__grounding__\", grounding), guardrails=False)\n",
    "print(f\"AI: {generated_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb7d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse CoT responses, loop into each workflow steps to execute"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
